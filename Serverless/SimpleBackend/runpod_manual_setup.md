# ðŸš€ **MANUAL RUNPOD DEPLOYMENT - SIMPLE BACKEND**

## âœ… **OBRAZ DOCKER GOTOWY:**
- Image: `mateoxin/simple-runpod-test:v2`
- Status: âœ… Pushed to Docker Hub

## ðŸŽ¯ **KROK 1: UtwÃ³rz Template na RunPod**

1. **PrzejdÅº do RunPod Console:** https://www.runpod.io/console
2. **Serverless** â†’ **Templates** â†’ **New Template**
3. **WypeÅ‚nij konfiguracjÄ™:**

```
Template Name: simple-backend-test
Container Image: mateoxin/simple-runpod-test:v2
Container Registry Credentials: (leave empty for public)

Container Configuration:
- Container Disk: 5 GB
- Expose HTTP Ports: 8000
- Expose TCP Ports: (leave empty)

Environment Variables:
- PYTHONUNBUFFERED = 1

Docker Command: (leave empty - uses CMD from Dockerfile)
```

4. **Save Template**

## ðŸŽ¯ **KROK 2: UtwÃ³rz Endpoint**

1. **Serverless** â†’ **Endpoints** â†’ **New Endpoint**
2. **Wybierz utworzony template:** `simple-backend-test`
3. **Konfiguracja endpointu:**

```
Endpoint Name: simple-backend-3090
GPU Configuration:
- GPU Type: RTX 3090
- GPU Count: 1

Scaling Configuration:
- Min Workers: 0
- Max Workers: 1
- Idle Timeout: 5 seconds
- Scale Type: Queue Delay
- Scale Value: 1

Advanced Settings:
- Request Timeout: 60 seconds
- Container Startup Timeout: 60 seconds
```

4. **Create Endpoint**

## ðŸŽ¯ **KROK 3: Przetestuj Endpoint**

Po utworzeniu endpointu otrzymasz:
- **Endpoint ID**: (np. `xyz123abc456`)
- **Endpoint URL**: `https://api.runpod.ai/v2/xyz123abc456`

### **Test 1: Health Check**
```bash
curl -X POST https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/runsync \
  -H "Authorization: Bearer YOUR_RUNPOD_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"input": {"type": "health"}}'
```

**Spodziewany wynik:**
```json
{
  "status": "COMPLETED",
  "output": {
    "status": "healthy",
    "timestamp": "2024-01-30T...",
    "message": "Simple backend is working!"
  }
}
```

### **Test 2: Ping Test**
```bash
curl -X POST https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/runsync \
  -H "Authorization: Bearer YOUR_RUNPOD_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"input": {"type": "ping"}}'
```

### **Test 3: Echo Test**
```bash
curl -X POST https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/runsync \
  -H "Authorization: Bearer YOUR_RUNPOD_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"input": {"type": "echo", "message": "Hello RunPod!"}}'
```

## ðŸŽ¯ **KROK 4: Zaktualizuj Config**

Po utworzeniu endpointu, zaktualizuj pliki konfiguracyjne:

```bash
# W pliku Serverless/Testing/config.env
RUNPOD_ENDPOINT_ID=YOUR_NEW_ENDPOINT_ID

# W pliku Serverless/SimpleTest/config.env  
RUNPOD_ENDPOINT_ID=YOUR_NEW_ENDPOINT_ID
```

## ðŸ§ª **KROK 5: Uruchom Automatyczne Testy**

```bash
cd Serverless/SimpleTest
python test_simple_backend.py
```

## ðŸ“Š **MONITORING**

1. **RunPod Console** â†’ **Serverless** â†’ **Endpoints**
2. **Kliknij na endpoint** â†’ **Metrics**
3. **SprawdÅº:**
   - Request count
   - Response times
   - Errors
   - Costs

## ðŸ’° **KOSZTY (RTX 3090)**

- **Idle**: $0.00/min (0 workers)
- **Active**: ~$0.50/min podczas pracy
- **Tip**: Ustaw `Max Workers: 1` Å¼eby ograniczyÄ‡ koszty

## ðŸ”§ **TROUBLESHOOTING**

### **Problem: Container nie startuje**
```bash
# SprawdÅº logi w RunPod Console
# Lub przetestuj lokalnie:
docker run -p 8000:8000 mateoxin/simple-runpod-test:v2
```

### **Problem: Timeout na requests**
- ZwiÄ™ksz `Request Timeout` w konfiguracji endpointu
- SprawdÅº czy handler odpowiada szybko

### **Problem: High costs**
- Ustaw `Min Workers: 0` 
- Zmniejsz `Idle Timeout`
- UÅ¼yj cheaper GPU (A40 zamiast 3090)

---

## ðŸŽ‰ **ENDPOINT GOTOWY!**

Po wykonaniu tych krokÃ³w bÄ™dziesz miaÅ‚:
âœ… DziaÅ‚ajÄ…cy endpoint z RTX 3090
âœ… 1 worker maximum
âœ… Gotowy do testowania
âœ… Minimalne koszty (auto-scale to 0)

**Next:** Przetestuj wszystkie funkcje i sprawdÅº monitoring! 